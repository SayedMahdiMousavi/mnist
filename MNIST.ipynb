{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pcqW-rOQCWv8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.flatten import Flatten\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvsZm65TFAGr"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R5Wl8LfxE_3U"
      },
      "outputs": [],
      "source": [
        "batchsize = 100\n",
        "num_class = 10\n",
        "lr = 0.001\n",
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wQJn0TboVnVl"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy7XbpqlDiXa"
      },
      "source": [
        "# **Create and read Dataset MNIST**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZKsa3F1GDcie"
      },
      "outputs": [],
      "source": [
        "train_data = torchvision.datasets.MNIST(root='./datasets',\n",
        "                                        train=True,\n",
        "                                        transform=transforms.ToTensor(),\n",
        "                                        download=True)\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root='./datasets',\n",
        "                                       train=False,\n",
        "                                       transform=transforms.ToTensor(),\n",
        "                                       download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                           batch_size=batchsize,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                          batch_size=batchsize,\n",
        "                                          shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGDEUukGGI-b"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YjhRnXoLY9Dv"
      },
      "outputs": [],
      "source": [
        "def cnn():\n",
        "  network = nn.Sequential(\n",
        "                          nn.Conv2d(1, 16, 3, stride=1, padding=1),\n",
        "                          nn.ReLU(),\n",
        "\n",
        "                          nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
        "                          nn.ReLU(),\n",
        "                          nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n",
        "\n",
        "                          Flatten(),\n",
        "\n",
        "                          nn.Linear(32 * 14 * 14, num_class))\n",
        "  return network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Decorator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_time(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = datetime.now()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = datetime.now()\n",
        "        duration = end_time - start_time\n",
        "        \n",
        "        hour = duration.seconds//3600\n",
        "        minute = duration.seconds//60\n",
        "        secend = duration.seconds%60\n",
        "        print(f'Total Time: {hour} : {minute} : {secend}')\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    return wrapper\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o2s8uBgId9h"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ui3yPJm8Ijbv"
      },
      "outputs": [],
      "source": [
        "model = cnn().to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "total_loss = []\n",
        "\n",
        "\n",
        "@log_time\n",
        "def train(epoch, optimizer):\n",
        "    \n",
        "    global total_loss\n",
        "    total_loss = []\n",
        "    \n",
        "    optimizer = optimizer(model.parameters(), lr=lr)\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    for i in range(epoch):\n",
        "        model.train()\n",
        "        for j, (imgs, labels) in enumerate(train_loader):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            out = model(imgs)\n",
        "            loss_value = loss_function(out, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            if (j+1) % 10 == 0:\n",
        "                total_loss.append(loss_value)\n",
        "                print(f'Train, Epoch [{i+1}/{epoch}] Loss: {loss_value.item():.2f}')\n",
        "\n",
        "            if j == 10:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgpOTTLjA5tD",
        "outputId": "83e6660d-fa56-458d-b264-4a5db4a0e903"
      },
      "outputs": [],
      "source": [
        "train(num_epochs, torch.optim.Adam)\n",
        "\n",
        "loss_adam = []\n",
        "for i in total_loss:\n",
        "    loss_adam.append(i.item())\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Total Loss\")\n",
        "plt.plot(loss_adam, label=\"Loss Adam\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGeuhOEpwS30"
      },
      "source": [
        "## RMSprop Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7_lJYJEmFxq",
        "outputId": "3e69b9d7-56a0-432d-cbe2-1d3282716189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train, Epoch [1/50] Loss: 1.90\n",
            "Train, Epoch [2/50] Loss: 0.97\n",
            "Train, Epoch [3/50] Loss: 0.89\n",
            "Train, Epoch [4/50] Loss: 0.41\n",
            "Train, Epoch [5/50] Loss: 0.35\n",
            "Train, Epoch [6/50] Loss: 0.43\n",
            "Train, Epoch [7/50] Loss: 0.31\n",
            "Train, Epoch [8/50] Loss: 0.27\n",
            "Train, Epoch [9/50] Loss: 0.42\n",
            "Train, Epoch [10/50] Loss: 0.24\n",
            "Train, Epoch [11/50] Loss: 0.22\n",
            "Train, Epoch [12/50] Loss: 0.30\n",
            "Train, Epoch [13/50] Loss: 0.32\n",
            "Train, Epoch [14/50] Loss: 0.18\n",
            "Train, Epoch [15/50] Loss: 0.20\n",
            "Train, Epoch [16/50] Loss: 0.10\n",
            "Train, Epoch [17/50] Loss: 0.15\n",
            "Train, Epoch [18/50] Loss: 0.08\n",
            "Train, Epoch [19/50] Loss: 0.13\n",
            "Train, Epoch [20/50] Loss: 0.08\n",
            "Train, Epoch [21/50] Loss: 0.19\n",
            "Train, Epoch [22/50] Loss: 0.12\n",
            "Train, Epoch [23/50] Loss: 0.28\n",
            "Train, Epoch [24/50] Loss: 0.19\n",
            "Train, Epoch [25/50] Loss: 0.15\n",
            "Train, Epoch [26/50] Loss: 0.15\n",
            "Train, Epoch [27/50] Loss: 0.12\n",
            "Train, Epoch [28/50] Loss: 0.11\n",
            "Train, Epoch [29/50] Loss: 0.16\n",
            "Train, Epoch [30/50] Loss: 0.07\n",
            "Train, Epoch [31/50] Loss: 0.05\n",
            "Train, Epoch [32/50] Loss: 0.11\n",
            "Train, Epoch [33/50] Loss: 0.09\n",
            "Train, Epoch [34/50] Loss: 0.07\n",
            "Train, Epoch [35/50] Loss: 0.07\n",
            "Train, Epoch [36/50] Loss: 0.12\n",
            "Train, Epoch [37/50] Loss: 0.09\n",
            "Train, Epoch [38/50] Loss: 0.11\n",
            "Train, Epoch [39/50] Loss: 0.06\n",
            "Train, Epoch [40/50] Loss: 0.09\n",
            "Train, Epoch [41/50] Loss: 0.19\n",
            "Train, Epoch [42/50] Loss: 0.11\n",
            "Train, Epoch [43/50] Loss: 0.08\n",
            "Train, Epoch [44/50] Loss: 0.09\n",
            "Train, Epoch [45/50] Loss: 0.05\n",
            "Train, Epoch [46/50] Loss: 0.24\n",
            "Train, Epoch [47/50] Loss: 0.09\n",
            "Train, Epoch [48/50] Loss: 0.07\n",
            "Train, Epoch [49/50] Loss: 0.05\n",
            "Train, Epoch [50/50] Loss: 0.19\n",
            "Total Time: 0 : 0 : 5\n"
          ]
        }
      ],
      "source": [
        "train(num_epochs, torch.optim.RMSprop)\n",
        "\n",
        "loss_rms = []\n",
        "for i in total_loss:\n",
        "    loss_rms.append(i.item())\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Total Loss\")\n",
        "plt.plot(loss_rms, label=\"Loss RMSprop\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nWhZfh3bPwk"
      },
      "source": [
        "## Newton Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06j5EnqUYbj6",
        "outputId": "dacde7c6-a5b1-4362-9df2-fa7ae26a6949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: backpack-for-pytorch in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from backpack-for-pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision<1.0.0,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from backpack-for-pytorch) (0.13.1+cu113)\n",
            "Requirement already satisfied: einops<1.0.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from backpack-for-pytorch) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.9.0->backpack-for-pytorch) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision<1.0.0,>=0.7.0->backpack-for-pytorch) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<1.0.0,>=0.7.0->backpack-for-pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision<1.0.0,>=0.7.0->backpack-for-pytorch) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1.0.0,>=0.7.0->backpack-for-pytorch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1.0.0,>=0.7.0->backpack-for-pytorch) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1.0.0,>=0.7.0->backpack-for-pytorch) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1.0.0,>=0.7.0->backpack-for-pytorch) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install backpack-for-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "24FVAQ5ZYZei"
      },
      "outputs": [],
      "source": [
        "from backpack import backpack, extend\n",
        "from backpack.extensions import DiagGGNMC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WlaN-SzGDJgs"
      },
      "outputs": [],
      "source": [
        "class NewtonOptimizer(torch.optim.Optimizer):\n",
        "    def __init__(self, parameters, step_size, damping):\n",
        "        super().__init__(parameters, dict(step_size=step_size, damping=damping))\n",
        "\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                step_direction = p.grad / (p.diag_ggn_mc + group[\"damping\"])\n",
        "                p.data.add_(step_direction, alpha=-group[\"step_size\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vmAfLtMCbc-0"
      },
      "outputs": [],
      "source": [
        "model_newton = cnn().to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = NewtonOptimizer(model_newton.parameters(), step_size=0.05, damping=1.)\n",
        "\n",
        "extend(model_newton)\n",
        "extend(loss_function)\n",
        "\n",
        "total_loss_newt = []\n",
        "\n",
        "@log_time\n",
        "def train_newton(epoch):\n",
        "  start_time = datetime.now()\n",
        "  for i in range(epoch):\n",
        "    model_newton.train()\n",
        "    for j, (imgs, labels) in enumerate(train_loader):\n",
        "      imgs = imgs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      out = model_newton(imgs)\n",
        "      loss_value = loss_function(out, labels)\n",
        "      model_newton.zero_grad()\n",
        "      \n",
        "      with backpack(DiagGGNMC()):\n",
        "        loss_value.backward()\n",
        "      optimizer.step()\n",
        "      if (j+1) % 10 == 0:\n",
        "        total_loss_newt.append(loss_value)\n",
        "        print(f'Train, Epoch [{i+1}/{epoch}] Loss: {loss_value.item():.2f}')\n",
        "\n",
        "      if j == 10:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvlKWQXfXDg0",
        "outputId": "041a7b43-4fb2-494b-a3e0-2194724e0237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train, Epoch [1/50] Loss: 2.13\n",
            "Train, Epoch [2/50] Loss: 1.40\n",
            "Train, Epoch [3/50] Loss: 1.01\n",
            "Train, Epoch [4/50] Loss: 0.68\n",
            "Train, Epoch [5/50] Loss: 1.04\n",
            "Train, Epoch [6/50] Loss: 0.58\n",
            "Train, Epoch [7/50] Loss: 1.29\n",
            "Train, Epoch [8/50] Loss: 0.52\n",
            "Train, Epoch [9/50] Loss: 0.55\n",
            "Train, Epoch [10/50] Loss: 0.37\n",
            "Train, Epoch [11/50] Loss: 0.33\n",
            "Train, Epoch [12/50] Loss: 0.46\n",
            "Train, Epoch [13/50] Loss: 0.32\n",
            "Train, Epoch [14/50] Loss: 0.45\n",
            "Train, Epoch [15/50] Loss: 0.48\n",
            "Train, Epoch [16/50] Loss: 0.30\n",
            "Train, Epoch [17/50] Loss: 0.22\n",
            "Train, Epoch [18/50] Loss: 0.46\n",
            "Train, Epoch [19/50] Loss: 0.34\n",
            "Train, Epoch [20/50] Loss: 0.50\n",
            "Train, Epoch [21/50] Loss: 0.40\n",
            "Train, Epoch [22/50] Loss: 0.33\n",
            "Train, Epoch [23/50] Loss: 0.32\n",
            "Train, Epoch [24/50] Loss: 0.31\n",
            "Train, Epoch [25/50] Loss: 0.40\n",
            "Train, Epoch [26/50] Loss: 0.25\n",
            "Train, Epoch [27/50] Loss: 0.32\n",
            "Train, Epoch [28/50] Loss: 0.32\n",
            "Train, Epoch [29/50] Loss: 0.25\n",
            "Train, Epoch [30/50] Loss: 0.23\n",
            "Train, Epoch [31/50] Loss: 0.31\n",
            "Train, Epoch [32/50] Loss: 0.28\n",
            "Train, Epoch [33/50] Loss: 0.31\n",
            "Train, Epoch [34/50] Loss: 0.29\n",
            "Train, Epoch [35/50] Loss: 0.28\n",
            "Train, Epoch [36/50] Loss: 0.19\n",
            "Train, Epoch [37/50] Loss: 0.16\n",
            "Train, Epoch [38/50] Loss: 0.15\n",
            "Train, Epoch [39/50] Loss: 0.15\n",
            "Train, Epoch [40/50] Loss: 0.06\n",
            "Train, Epoch [41/50] Loss: 0.26\n",
            "Train, Epoch [42/50] Loss: 0.18\n",
            "Train, Epoch [43/50] Loss: 0.19\n",
            "Train, Epoch [44/50] Loss: 0.24\n",
            "Train, Epoch [45/50] Loss: 0.18\n",
            "Train, Epoch [46/50] Loss: 0.27\n",
            "Train, Epoch [47/50] Loss: 0.22\n",
            "Train, Epoch [48/50] Loss: 0.15\n",
            "Train, Epoch [49/50] Loss: 0.15\n",
            "Train, Epoch [50/50] Loss: 0.15\n",
            "Total Time: 0 : 0 : 8\n"
          ]
        }
      ],
      "source": [
        "train_newton(num_epochs)\n",
        "\n",
        "loss_newt = []\n",
        "for i in total_loss:\n",
        "    loss_newt.append(i.item())\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Total Loss\")\n",
        "plt.plot(loss_newt, label=\"Loss Newton\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIa4S6LyUSS-"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-6Eq1J8UToW",
        "outputId": "7fa36927-e3fc-4b21-b0fd-9f3bb680f9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [100/600] Acc 97.4400\n",
            "Step [200/600] Acc 97.4200\n",
            "Step [300/600] Acc 97.4800\n",
            "Step [400/600] Acc 97.5975\n",
            "Step [500/600] Acc 97.6060\n",
            "Step [600/600] Acc 97.6100\n"
          ]
        }
      ],
      "source": [
        "model_adam.eval()\n",
        "corrects1 = 0\n",
        "num_steps = len(test_loader)\n",
        "\n",
        "for j, (imgs, labels) in enumerate(test_loader):\n",
        "  imgs = imgs.to(device)\n",
        "  labels = labels.to(device)\n",
        "  out = model_adam(imgs)\n",
        "  predicted1 = torch.argmax(out, 1)\n",
        "  corrects1 += torch.sum(predicted1 == labels)\n",
        "  if (j+1) % 100 == 0:\n",
        "    accuracy1 = 100*corrects1/((j+1)*batchsize)\n",
        "    print(f'Step [{j+1}/{num_steps}] Acc {accuracy1:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRrBjkTOY2tm"
      },
      "source": [
        "# Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qnX1HfTlP5zi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Total Loss\")\n",
        "plt.plot(loss_adam, label=\"Loss Adam\")\n",
        "plt.plot(loss_rms, label=\"Loss RMSprop\")\n",
        "plt.plot(loss_newt, label=\"Loss Newton\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "d75a0a914c662ebf6803487d29aeab48d7971b9da6ab263cd55cfdbc9ed51b7a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
